{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbubakrIbrahim/BERT-and-LIME-approach-for-Fake-News-2023-2023/blob/main/New_version_BERT_and_LIME_for_Detection_Fake_and_Real_News.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqaPyC1-5QmK"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "\n",
        "import transformers\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing Libraries ##############################\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "id": "Q54xfDEhFHCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.read_csv('/content/spam.csv', encoding='latin-1')\n",
        "#df.head()\n"
      ],
      "metadata": {
        "id": "cE3UBHrb5wru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fake news\n",
        "#df = pd.read_csv('/content/fake_or_real_news.csv', encoding='latin-1')\n",
        "#df.head()\n"
      ],
      "metadata": {
        "id": "jTlsi2iSmKbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Covid 19 fake and real news dataset\n",
        "df = pd.read_csv('/content/Last_Version_Real_AND_FAKE_NEWS_24.csv', encoding='latin-1')\n",
        "df.head(5)\n"
      ],
      "metadata": {
        "id": "Ab6yBbeceR1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######Preprocessing stage################################\n",
        "# Remove Rows with NaN Values\n",
        "df_cleaned = df.dropna()\n",
        "df_cleaned.head(9)"
      ],
      "metadata": {
        "id": "JptHU3uBi63a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove special characters, numbers, and extra whitespaces\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Stemming using Porter Stemmer\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    # Join the tokens back into a string\n",
        "    processed_text = ' '.join(tokens)\n",
        "\n",
        "    return processed_text\n",
        "\n",
        "# Example usage\n",
        "original_text = xz\n",
        "text = preprocess_text(original_text)\n",
        "\n",
        "print(\"Original Text:\")\n",
        "print(original_text)\n",
        "print(\"\\nProcessed Text:\")\n",
        "print(text)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "mNHKH1NqjpDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.shape\n"
      ],
      "metadata": {
        "id": "Qyh2EyGk5wur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.info()\n"
      ],
      "metadata": {
        "id": "UvmK6EjU5wy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "OagpIC9u5w56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.drop(['Unnamed: 0'], axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "khJF0Lafmh_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.rename(columns={'label': 'Class'}, inplace=True)\n"
      ],
      "metadata": {
        "id": "QppI1ssizLVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.head()\n"
      ],
      "metadata": {
        "id": "_yXq6OmIzLfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df['label'] = df['label'].map({'REAL':0, 'FAKE':1})\n",
        "#df.head()\n"
      ],
      "metadata": {
        "id": "IrPfhKjXzLh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df['text'][2]\n"
      ],
      "metadata": {
        "id": "4yFyO17XzLkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.isna().sum()\n"
      ],
      "metadata": {
        "id": "3ErJSTOYza6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df['Class'].value_counts()\n"
      ],
      "metadata": {
        "id": "tA_swem3za9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style = \"darkgrid\" , font_scale = 1.2)\n",
        "#sns.countplot(df.Class).set_title(\"Number of REAL and FAKE messages\")\n",
        "#plt.show()\n"
      ],
      "metadata": {
        "id": "Uk-wbm-VzbEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.describe()\n"
      ],
      "metadata": {
        "id": "IOoVde-6zbHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sms = pd.value_counts(df[\"label\"], sort=True)\n",
        "#sms.plot(kind=\"pie\", labels=[\"ham\", \"spam\"], autopct=\"%1.0f%%\")\n",
        "\n",
        "#plt.title(\"SMS messages Distribution\")\n",
        "#plt.ylabel(\"\")\n",
        "#plt.show()\n"
      ],
      "metadata": {
        "id": "t13SzwLHzbJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above 87% of these SMS messages are ham (legitimate) and 13% of them are spam.\n",
        "\n"
      ],
      "metadata": {
        "id": "Fs4Fh_zJgs6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XvqdiGXegrd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_cleaned['length'] = df.text.apply(len)\n",
        "#df_cleaned.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "jaeFMnmIzLnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.figure(figsize=(8, 5))\n",
        "#df[df.Class == 0].length.plot(bins=35, kind='hist', color='blue', label='REAL', alpha=0.6)\n",
        "#df[df.Class == 1].length.plot(kind='hist', color='red', label='FAKE', alpha=0.6)\n",
        "#plt.legend()\n",
        "#plt.xlabel(\"Messages Length\");\n"
      ],
      "metadata": {
        "id": "empEz8iDz0jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now let's see if the length has an influence on messages spam or ham:\n",
        "\n",
        "\n",
        "#_, ax = plt.subplots(figsize=(10, 4))\n",
        "#sns.kdeplot(df.loc[df.Class == 0, \"length\"], shade=True, label=\"REAL\", clip=(-50, 250),)\n",
        "#sns.kdeplot(df.loc[df.Class == 1, \"length\"], shade=True, label=\"FAKE\")\n",
        "#ax.set(\n",
        " #   xlabel=\"Length\",\n",
        "  #  ylabel=\"Density\",\n",
        "   # title=\"Length of messages.\",\n",
        "#)\n",
        "#ax.legend(loc=\"upper right\")\n",
        "#plt.show()\n"
      ],
      "metadata": {
        "id": "l0xBpzByz0ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stop_words = stopwords.words('english')\n",
        "#print(stop_words[::10])\n",
        "\n",
        "#porter = PorterStemmer()"
      ],
      "metadata": {
        "id": "8mL1nfpJz0q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ovKOPYGn3a2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def clean_text(words):\n",
        " #   \"\"\"The function to clean text\"\"\"\n",
        "  #  words = re.sub(\"[^a-zA-Z]\",\" \", words)\n",
        "   # text = words.lower().split()\n",
        "    #return \" \".join(text)\n",
        "\n",
        "#def remove_stopwords(text):\n",
        " #   \"\"\"The function to removing stopwords\"\"\"\n",
        "  #  text = [word.lower() for word in text.split() if word.lower() not in stop_words]\n",
        "   # return \" \".join(text)\n",
        "\n",
        "#def stemmer(stem_text):\n",
        " #   \"\"\"The function to apply stemming\"\"\"\n",
        "  #  stem_text = [porter.stem(word) for word in stem_text.split()]\n",
        "   # return \" \".join(stem_text)"
      ],
      "metadata": {
        "id": "UqmOQmFBz0tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\"\"\"\n",
        "#df['text'] = df['text'].apply(clean_text)\n",
        "#df['text'] = df['text'].apply(remove_stopwords)\n",
        "#df['text'] = df['text'].apply(stemmer)\n",
        "#\"\"\""
      ],
      "metadata": {
        "id": "EbClOGP4JBMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.head()"
      ],
      "metadata": {
        "id": "Md9Me-OuJBOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(df_cleaned['text'].apply(lambda x: len(x.split(' '))).sum())"
      ],
      "metadata": {
        "id": "03iD8ixSJBQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################Build Bert Model#####################################"
      ],
      "metadata": {
        "id": "_N4I6C7bJBTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
        "tokenizer\n"
      ],
      "metadata": {
        "id": "zRUSPTlkJBWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "1tPShnLRJPzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.head(1)"
      ],
      "metadata": {
        "id": "LezTA9qhG8_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Covid 19 fake and real news dataset\n",
        "df = pd.read_csv('/content/Last_Version_Real_AND_FAKE_NEWS_24.csv', encoding='latin-1')\n",
        "df.head(11724)\n"
      ],
      "metadata": {
        "id": "w4lHkH7FQQl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the context of fake and real News\n",
        "from typing import Text\n",
        "X21=df['text'] + df['source']+ df['hashtags']+ df['user_description']+df['user_location']\n",
        "y=df['user_verified']\n",
        "y"
      ],
      "metadata": {
        "id": "E5NtU_cj3V-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the context of fake and real News\n",
        "from typing import Text\n",
        "X1=df_cleaned['text'] + df_cleaned['source']+ df_cleaned['hashtags']+ df_cleaned['user_description']+df_cleaned['user_location']\n",
        "y=df_cleaned['user_verified']\n",
        "y"
      ],
      "metadata": {
        "id": "SfNwMyThQssk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the context of fake and real News\n",
        "#from typing import Text\n",
        "#X1=df_cleaned['text'] + df_cleaned['source']+ df_cleaned['hashtags']+ df_cleaned['user_description']+df_cleaned['user_location']\n",
        "#y=df_cleaned['Label']\n"
      ],
      "metadata": {
        "id": "EMVmm9kJJP2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vlfw5d6dRBEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X1, y, test_size=0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "jAQpfkEGJP4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text, maxlen):\n",
        "  input_ids=[]\n",
        "  attention_masks=[]\n",
        "\n",
        "  for row in text:\n",
        "    encoded = tokenizer.encode_plus(\n",
        "        row,\n",
        "        add_special_tokens=True,\n",
        "        max_length=maxlen,\n",
        "        pad_to_max_length=True,\n",
        "        return_attention_mask=True,\n",
        "    )\n",
        "    input_ids.append(encoded['input_ids'])\n",
        "    attention_masks.append(encoded['attention_mask'])\n",
        "\n",
        "  return np.array(input_ids),np.array(attention_masks)\n"
      ],
      "metadata": {
        "id": "F02Cbz9dJP7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train_input_ids, X_train_attention_masks = encode(X_train.values, maxlen=64)\n",
        "X_test_input_ids, X_test_attention_masks = encode(X_test.values, maxlen=64)"
      ],
      "metadata": {
        "id": "Yji6iqdYJP-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(bert_model):\n",
        "   input_word_ids = tf.keras.Input(shape=(64,),dtype='int32')\n",
        "   attention_masks = tf.keras.Input(shape=(64,),dtype='int32')\n",
        "\n",
        "   sequence_output = bert_model([input_word_ids,attention_masks])\n",
        "   output = sequence_output[1]\n",
        "   output = tf.keras.layers.Dense(32,activation='relu')(output)\n",
        "   output = tf.keras.layers.Dropout(0.2)(output)\n",
        "   output = tf.keras.layers.Dense(1,activation='sigmoid')(output)\n",
        "\n",
        "   model = tf.keras.models.Model(inputs = [input_word_ids,attention_masks], outputs = output)\n",
        "   model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "   return model"
      ],
      "metadata": {
        "id": "iGRVtCMEJQAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(bert_model)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "CuJw9e6BJQDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class_weight = {0: 1, 1: 8}\n"
      ],
      "metadata": {
        "id": "dSenbUCFJQGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "#mixed_precision.set_global_policy(‘mixed_float16’)\n",
        "mixed_precision.set_global_policy('mixed_float16')\n"
      ],
      "metadata": {
        "id": "Vcxu3njxx3JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qJbqpX_aJoHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "6zwL-262JoJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "loss, accuracy = model.evaluate([X_test_input_ids, X_test_attention_masks], y_test)\n",
        "print('Test accuracy :', accuracy)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "N4gwY1GPJoMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the CountVectorizer method\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "X_train = X_train.fillna('')\n",
        "\n",
        "count_vector = CountVectorizer()\n",
        "\n",
        "# Fit the training data and then return the matrix\n",
        "training_data = count_vector.fit_transform(X_test) # Fit will make it as dictionry of words\n",
        "\n",
        "# Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
        "testing_data = count_vector.transform(X_test)"
      ],
      "metadata": {
        "id": "wdF4uw5XId78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_train_tfidf.shape"
      ],
      "metadata": {
        "id": "hg3rn833Ino9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_clf = RandomForestClassifier(n_estimators=1000, random_state=10)\n",
        "rf_clf.fit(X_test, y_train)\n",
        "y_pred = rf_clf.predict(testing_data)"
      ],
      "metadata": {
        "id": "sCOTlGLrIqMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "#print(confusion_matrix(y_test,y_pred))\n"
      ],
      "metadata": {
        "id": "9Wx_SAzILoMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.head(1)"
      ],
      "metadata": {
        "id": "dVDjTM-tJBq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd= 'Give $2000/month to every American #moneyforthepeople #covid19 - Sign the Petition! https://t.co/06KW5ZIGpe via @Change'"
      ],
      "metadata": {
        "id": "8aV2zZD1PU0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oBt5ljpbPUKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1= df_cleaned['user_description'] + df_cleaned['user_created'] + \"  \" +  df_cleaned['text'] + df_cleaned['hashtags']+ \"  \"+df_cleaned['user_location']+ \"  \" + df_cleaned['source']\n"
      ],
      "metadata": {
        "id": "yyJlH8w8IrkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "News_value=X21.iloc[11723]\n",
        "News_value"
      ],
      "metadata": {
        "id": "cAR_9CmaIrv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######XAI(LIME) Module #####################################"
      ],
      "metadata": {
        "id": "9KGBzup7LGxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime\n"
      ],
      "metadata": {
        "id": "W9XO0A9CJoOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lime\n",
        "from lime import lime_text\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "import lime.lime_tabular\n",
        "from lime import lime_text\n",
        "from sklearn.pipeline import make_pipeline\n",
        "c = make_pipeline(count_vector, rf_clf)\n",
        "\n"
      ],
      "metadata": {
        "id": "Be04bsmOJoRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_proba(text):\n",
        "    # Preprocess the text if needed\n",
        "    # Tokenize and create input_ids, attention_masks for the model\n",
        "    input_ids, attention_masks = preprocess_text(text)\n",
        "\n",
        "    # Make predictions using your trained model\n",
        "    predictions = model.predict([input_ids, attention_masks])\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "bpFhBEPDz0v_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = LimeTextExplainer(class_names=[\"REAL_NEWS \", \"FAKE_NEWS\"])\n"
      ],
      "metadata": {
        "id": "THSME_JypFDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the context of fake and real News\n",
        "from typing import Text\n",
        "X21=df['text'] + df['source']+df['user_location']#+ #df['hashtags']+ df['user_description']\n",
        "y=df['user_verified']\n"
      ],
      "metadata": {
        "id": "k6O6UT2wSEJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "News_value=X21.iloc[11723]\n",
        "News_value = News_value +' is user_location'\n",
        "News_value"
      ],
      "metadata": {
        "id": "Bz_r08WApRwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vKMeUsPRRvV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lime\n",
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "\n",
        "# Load your machine learning model (ensure it has predict_proba method)\n",
        "model = rf_clf  # Replace with your trained model\n",
        "\n",
        "# Create a LIME explainer\n",
        "explainer = LimeTabularExplainer(training_data, mode=\"classification\")\n",
        "\n",
        "# Choose an email instance to explain (replace with your own data)\n",
        "email_instance = News_value\n",
        "explainer = LimeTextExplainer(class_names=['FAKE News','REAL NEWS'])\n",
        "\n",
        "\n",
        "# Get the predicted probabilities using LIME\n",
        "#predicted_probabilities = explainer.explain_instance( email_instance, c.predict_proba)\n",
        "#predicted_probabilities\n",
        "\n",
        "predicted_probabilities = explainer.explain_instance(\n",
        "    email_instance, c.predict_proba, num_features=10)\n",
        "\n"
      ],
      "metadata": {
        "id": "19Q__BkUpbp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam_probability = predicted_probabilities.local_pred[0]   # Probability of being NEWS\n"
      ],
      "metadata": {
        "id": "2mpBsi5qMUhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_probabilities.as_list()"
      ],
      "metadata": {
        "id": "z9J8p8ifMUrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "fig = predicted_probabilities.as_pyplot_figure()\n"
      ],
      "metadata": {
        "id": "wD_qnFd5MUuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_probabilities.show_in_notebook(text=False)\n"
      ],
      "metadata": {
        "id": "c61Q5dzzMUwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_probabilities.show_in_notebook(text=True)"
      ],
      "metadata": {
        "id": "_rZO1EFXMnZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Covid 19 fake and real news dataset\n",
        "df = pd.read_csv('/content/Last_Version_Real_AND_FAKE_NEWS_24.csv', encoding='latin-1')\n",
        "df.head(10000)\n"
      ],
      "metadata": {
        "id": "ihgAsBuwIdUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GGVDVg4iUrl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "News_value\n",
        "\n",
        "News_value= df['text'].iloc[11552]\n",
        "\n",
        "News_value"
      ],
      "metadata": {
        "id": "gnab1c3oVl8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X11=df_cleaned['text']#+df_cleaned['user_description']+df_cleaned['hashtags']+\"  \"+ df_cleaned['source']+\"  \"+df_cleaned['user_created']+\"  \"+df_cleaned['date']"
      ],
      "metadata": {
        "id": "uZxgJZyUOiT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "News_value=X11.iloc[4]\n",
        "News_value"
      ],
      "metadata": {
        "id": "sAijtY2NNMgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Choose an email instance to explain (replace with your own data)\n",
        "email_instance = News_value\n",
        "explainer = LimeTextExplainer(class_names=['Fake NEWS','Real News'])\n",
        "\n",
        "\n",
        "# Get the predicted probabilities using LIME\n",
        "#predicted_probabilities = explainer.explain_instance( email_instance, c.predict_proba)\n",
        "#predicted_probabilities\n",
        "\n",
        "predicted_probabilities = explainer.explain_instance(\n",
        "    email_instance, model.predict_proba, num_features=10)\n",
        "\n",
        "spam_probability = predicted_probabilities.local_pred[0]   # Probability of being NEWS\n",
        "spam_probability"
      ],
      "metadata": {
        "id": "WR-n3eF5NStR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DoBA6Vl5ORpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_probabilities.as_list()"
      ],
      "metadata": {
        "id": "gUFyhPlmPUP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "fig = predicted_probabilities.as_pyplot_figure()\n"
      ],
      "metadata": {
        "id": "oJ40JXXaNj8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_probabilities.show_in_notebook(text=False)\n"
      ],
      "metadata": {
        "id": "ImZRnK6oMnft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_probabilities.show_in_notebook(text=True)\n"
      ],
      "metadata": {
        "id": "3xaIiM34NuYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "News_value\n",
        "\n",
        "News_value= df['text'].iloc[8012]\n",
        "\n",
        "News_value"
      ],
      "metadata": {
        "id": "ZCf2RyFqGoRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5LgQYJ9g5GcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Choose an email instance to explain (replace with your own data)\n",
        "email_instance = News_value\n",
        "explainer = LimeTextExplainer(class_names=['FAKE NEWS','REAL News'])\n",
        "\n",
        "\n",
        "# Get the predicted probabilities using LIME\n",
        "#predicted_probabilities = explainer.explain_instance( email_instance, c.predict_proba)\n",
        "#predicted_probabilities\n",
        "\n",
        "predicted_probabilities = explainer.explain_instance(\n",
        "    email_instance, c.predict_proba, num_features=10)\n",
        "\n",
        "spam_probability = predicted_probabilities.local_pred[0]   # Probability of being NEWS\n",
        "spam_probability"
      ],
      "metadata": {
        "id": "1iYCTBDnPlJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "fig = predicted_probabilities.as_pyplot_figure()\n"
      ],
      "metadata": {
        "id": "PLFU_zImP20G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_probabilities.show_in_notebook(text=False)\n"
      ],
      "metadata": {
        "id": "zwy1-yySQFCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_probabilities.show_in_notebook(text=True)\n"
      ],
      "metadata": {
        "id": "rcs2GNJCQJLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "News_value\n",
        "\n",
        "News_value= df['text'].iloc[121\n",
        "                          ]\n",
        "\n",
        "News_value"
      ],
      "metadata": {
        "id": "R36_NphZQc6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "News_value=X11.iloc[1203]\n",
        "News_value\n",
        "# Choose an email instance to explain (replace with your own data)\n",
        "email_instance = News_value\n",
        "explainer = LimeTextExplainer(class_names=['FAKE NEWS','REAL News'])\n",
        "\n",
        "\n",
        "# Get the predicted probabilities using LIME\n",
        "#predicted_probabilities = explainer.explain_instance( email_instance, c.predict_proba)\n",
        "#predicted_probabilities\n",
        "\n",
        "predicted_probabilities = explainer.explain_instance(\n",
        "    email_instance, c.predict_proba, num_features=10)\n",
        "\n",
        "spam_probability = predicted_probabilities.local_pred[0]   # Probability of being NEWS\n",
        "spam_probability"
      ],
      "metadata": {
        "id": "tLN-O6uyQVDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "fig = predicted_probabilities.as_pyplot_figure()\n"
      ],
      "metadata": {
        "id": "bzoEZY0KQaYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_probabilities.show_in_notebook(text=False)\n"
      ],
      "metadata": {
        "id": "eIkxp6v_Qfxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HjxtlOLSSTXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_probabilities.show_in_notebook(text=True)\n"
      ],
      "metadata": {
        "id": "im-3GQpJQewS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "News_value=X11.iloc[2201\n",
        "                  ]\n",
        "News_value\n",
        "# Choose an email instance to explain (replace with your own data)\n",
        "email_instance = News_value\n",
        "explainer = LimeTextExplainer(class_names=['FAKE News','REAL NEWS'])\n",
        "\n",
        "\n",
        "# Get the predicted probabilities using LIME\n",
        "#predicted_probabilities = explainer.explain_instance( email_instance, c.predict_proba)\n",
        "#predicted_probabilities\n",
        "\n",
        "predicted_probabilities = explainer.explain_instance(\n",
        "    email_instance, c.predict_proba, num_features=10)\n",
        "\n",
        "spam_probability = predicted_probabilities.local_pred[0]   # Probability of being NEWS\n",
        "spam_probability"
      ],
      "metadata": {
        "id": "l70FrPh_Rjq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "fig = predicted_probabilities.as_pyplot_figure()\n"
      ],
      "metadata": {
        "id": "jvaMcgOcSQwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bZ4627MQTcZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_probabilities.show_in_notebook(text=False)\n"
      ],
      "metadata": {
        "id": "fx9bmjUdSUJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_probabilities.show_in_notebook(text=True)\n"
      ],
      "metadata": {
        "id": "OXuNIJypFkAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y5yWQNrETZY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FNalYkKcTdWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pjyP_f4HSYQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FxbZE1yUUHAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZTeUwWRUTvJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "fig = predicted_probabilities.as_pyplot_figure()\n"
      ],
      "metadata": {
        "id": "YhPMdP9DULii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_probabilities.show_in_notebook(text=False)\n"
      ],
      "metadata": {
        "id": "UlJ5of6GUcAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_probabilities.show_in_notebook(text=True)\n"
      ],
      "metadata": {
        "id": "pXWJZRZ5Ugki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ecd-ZCGEUgsd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}